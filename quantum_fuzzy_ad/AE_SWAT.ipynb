{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 12:07:46.312629: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739272066.349865 3958020 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739272066.362223 3958020 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 12:07:46.446849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3958020/4193474766.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['OUTCOME'].replace(to_replace = ['A ttack', 'Attack'], value = 1, inplace = True)\n",
      "/tmp/ipykernel_3958020/4193474766.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['OUTCOME'].replace(to_replace = ['Normal'], value = 0, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>...</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P602</th>\n",
       "      <th>OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.614181</td>\n",
       "      <td>-0.671446</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>1.471050</td>\n",
       "      <td>-1.150246</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.656906</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307535</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.296326</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.302691</td>\n",
       "      <td>1.542312</td>\n",
       "      <td>0.315175</td>\n",
       "      <td>-0.102994</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650194</td>\n",
       "      <td>-0.671760</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>1.471050</td>\n",
       "      <td>-1.166990</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.654185</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296729</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>1.542312</td>\n",
       "      <td>0.315175</td>\n",
       "      <td>-0.102994</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688088</td>\n",
       "      <td>-0.670819</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>1.471050</td>\n",
       "      <td>-1.166990</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.654185</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258144</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>1.542312</td>\n",
       "      <td>0.313825</td>\n",
       "      <td>-0.102994</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717382</td>\n",
       "      <td>-0.666747</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>1.471050</td>\n",
       "      <td>-1.166990</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.654866</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258144</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>1.542312</td>\n",
       "      <td>0.311464</td>\n",
       "      <td>-0.102994</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.750975</td>\n",
       "      <td>-0.663615</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>1.471050</td>\n",
       "      <td>-1.166990</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.655772</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232678</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.300874</td>\n",
       "      <td>1.542312</td>\n",
       "      <td>0.311464</td>\n",
       "      <td>-0.102994</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449914</th>\n",
       "      <td>0.709588</td>\n",
       "      <td>-0.698073</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>-1.200282</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>0.669378</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281680</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.307359</td>\n",
       "      <td>-0.359522</td>\n",
       "      <td>0.301340</td>\n",
       "      <td>-0.103797</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449915</th>\n",
       "      <td>0.700450</td>\n",
       "      <td>-0.691181</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>-1.200282</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>0.669378</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232678</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.306062</td>\n",
       "      <td>-0.359522</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.103797</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449916</th>\n",
       "      <td>0.685669</td>\n",
       "      <td>-0.688989</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>-1.200282</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>0.669945</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223033</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.306062</td>\n",
       "      <td>-0.359522</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.103797</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449917</th>\n",
       "      <td>0.677068</td>\n",
       "      <td>-0.688675</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>-1.200282</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>0.669945</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.306062</td>\n",
       "      <td>-0.359522</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.103797</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449918</th>\n",
       "      <td>0.660674</td>\n",
       "      <td>-0.685543</td>\n",
       "      <td>0.693862</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>-0.083632</td>\n",
       "      <td>-1.200282</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>0.668244</td>\n",
       "      <td>0.655352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232678</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.302658</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.306062</td>\n",
       "      <td>-0.359522</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.103797</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449918 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FIT101    LIT101     MV101      P101      P102    AIT201    AIT202  \\\n",
       "1       0.614181 -0.671446  0.693862  0.665191 -0.083632  1.471050 -1.150246   \n",
       "2       0.650194 -0.671760  0.693862  0.665191 -0.083632  1.471050 -1.166990   \n",
       "3       0.688088 -0.670819  0.693862  0.665191 -0.083632  1.471050 -1.166990   \n",
       "4       0.717382 -0.666747  0.693862  0.665191 -0.083632  1.471050 -1.166990   \n",
       "5       0.750975 -0.663615  0.693862  0.665191 -0.083632  1.471050 -1.166990   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "449914  0.709588 -0.698073  0.693862  0.665191 -0.083632 -1.200282  0.959110   \n",
       "449915  0.700450 -0.691181  0.693862  0.665191 -0.083632 -1.200282  0.959110   \n",
       "449916  0.685669 -0.688989  0.693862  0.665191 -0.083632 -1.200282  0.959110   \n",
       "449917  0.677068 -0.688675  0.693862  0.665191 -0.083632 -1.200282  0.959110   \n",
       "449918  0.660674 -0.685543  0.693862  0.665191 -0.083632 -1.200282  0.959110   \n",
       "\n",
       "          AIT203    FIT201     MV201  ...    FIT502    FIT503    FIT504  \\\n",
       "1       0.501006  0.656906  0.655352  ...  0.307535  0.294030  0.296326   \n",
       "2       0.501006  0.654185  0.655352  ...  0.296729  0.294030  0.306616   \n",
       "3       0.501006  0.654185  0.655352  ...  0.258144  0.294030  0.306616   \n",
       "4       0.501006  0.654866  0.655352  ...  0.258144  0.294030  0.306616   \n",
       "5       0.501006  0.655772  0.655352  ...  0.232678  0.294030  0.306616   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "449914 -1.105095  0.669378  0.655352  ...  0.281680  0.292003  0.281287   \n",
       "449915 -1.105095  0.669378  0.655352  ...  0.232678  0.292003  0.281287   \n",
       "449916 -1.105095  0.669945  0.655352  ...  0.223033  0.292003  0.281287   \n",
       "449917 -1.105095  0.669945  0.655352  ...  0.206055  0.292003  0.298701   \n",
       "449918 -1.105095  0.668244  0.655352  ...  0.232678  0.292003  0.302658   \n",
       "\n",
       "            P501    PIT501    PIT502    PIT503    FIT601      P602  OUTCOME  \n",
       "1       0.282974  0.302691  1.542312  0.315175 -0.102994 -0.095828        0  \n",
       "2       0.282974  0.302950  1.542312  0.315175 -0.102994 -0.095828        0  \n",
       "3       0.282974  0.302950  1.542312  0.313825 -0.102994 -0.095828        0  \n",
       "4       0.282974  0.302950  1.542312  0.311464 -0.102994 -0.095828        0  \n",
       "5       0.282974  0.300874  1.542312  0.311464 -0.102994 -0.095828        0  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "449914  0.282974  0.307359 -0.359522  0.301340 -0.103797 -0.095828        0  \n",
       "449915  0.282974  0.306062 -0.359522  0.299316 -0.103797 -0.095828        0  \n",
       "449916  0.282974  0.306062 -0.359522  0.299316 -0.103797 -0.095828        0  \n",
       "449917  0.282974  0.306062 -0.359522  0.299316 -0.103797 -0.095828        0  \n",
       "449918  0.282974  0.306062 -0.359522  0.299316 -0.103797 -0.095828        0  \n",
       "\n",
       "[449918 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/SWaT_Dataset_Attack_v0.csv\")\n",
    "\n",
    "df.columns = [\n",
    "\t'TIMESTAMP','FIT101','LIT101','MV101','P101','P102','AIT201','AIT202','AIT203','FIT201','MV201','P201','P202','P203',\n",
    "    'P204','P205','P206','DPIT301','FIT301','LIT301','MV301','MV302','MV303','MV304','P301','P302','AIT401','AIT402','FIT401',\n",
    "    'LIT401','P401','P402','P403','P404','UV401','AIT501','AIT502','AIT503','AIT504','FIT501','FIT502','FIT503','FIT504',\n",
    "    'P501','P502','PIT501','PIT502','PIT503','FIT601','P601','P602','P603','OUTCOME'\n",
    "]\n",
    "\n",
    "# The first row only contains labels\n",
    "# 'TIMESTAMP' is irrelevant for the thesis\n",
    "# The other dropped columns contain either only 0s, only 1s or only 2s and are therefore irrelevant\n",
    "\n",
    "df = df.iloc[1:]\n",
    "df = df.drop(['TIMESTAMP', 'P202', 'P301', 'P401', 'P404', 'P502', 'P601', 'P603'], axis = 1)\n",
    "\n",
    "# The dataset labels attacks by 'A ttack' and 'Attack', and labels normal data as 'Normal'\n",
    "# To keep the same structure in all datasets, the 'A ttack' and 'Attack' values are changed to '-1' and normal values to '1'\n",
    "\n",
    "df['OUTCOME'].replace(to_replace = ['A ttack', 'Attack'], value = 1, inplace = True)\n",
    "df['OUTCOME'].replace(to_replace = ['Normal'], value = 0, inplace = True)\n",
    "\n",
    "# data types need to be numeric to be encoded to z-scores --> convert column object data types to numerics\n",
    "\n",
    "cols = df.columns[df.columns != 'OUTCOME']\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Encoding the feature vectors to z-scores\n",
    "\n",
    "cols = list(df.columns[df.columns != 'OUTCOME'])\n",
    "for col in cols:\n",
    "    df[col] = ((df[col] - df[col].mean())/df[col].std(ddof=0))\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature più informative rispetto alle anomalie:\n",
      "   Feature  MI_Score\n",
      "5   AIT201  0.240373\n",
      "30  AIT501  0.220037\n",
      "29   UV401  0.210289\n",
      "38    P501  0.210171\n",
      "\n",
      "Feature selezionate: ['AIT201', 'AIT501', 'UV401', 'P501']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# 🔹 Definisci feature e target\n",
    "X = df.drop(columns=[\"OUTCOME\"])  # Tutte le colonne tranne il target\n",
    "y = df[\"OUTCOME\"]  # Target binario (0 = normale, 1 = anomalia)\n",
    "\n",
    "# 🔹 Calcola la Mutual Information\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "\n",
    "# 🔹 Crea un DataFrame con i risultati\n",
    "mi_results = pd.DataFrame({\"Feature\": X.columns, \"MI_Score\": mi_scores})\n",
    "\n",
    "# 🔹 Filtra solo le feature con MI > 0 (cioè, che portano informazione)\n",
    "threshold = 0.2098\n",
    "selected_features = mi_results[mi_results[\"MI_Score\"] > threshold]\n",
    "\n",
    "# 🔹 Ordina in base all'importanza\n",
    "selected_features = selected_features.sort_values(by=\"MI_Score\", ascending=False)\n",
    "\n",
    "# 🔹 Stampa le feature selezionate\n",
    "print(\"Feature più informative rispetto alle anomalie:\")\n",
    "print(selected_features)\n",
    "\n",
    "# 🔹 Se vuoi solo i nomi delle feature per usarle in MATLAB\n",
    "important_feature_names = selected_features[\"Feature\"].tolist()\n",
    "print(\"\\nFeature selezionate:\", important_feature_names)\n",
    "\n",
    "\n",
    "# Creating normal and attack masks\n",
    "normal_mask = df[df.OUTCOME == 0]\n",
    "attack_mask = df[df.OUTCOME == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponiamo che `df` sia il tuo DataFrame originale\n",
    "selected_features = ['AIT201', 'AIT501', 'UV401', 'P501']\n",
    "\n",
    "# Creiamo un nuovo DataFrame con solo queste feature + il target\n",
    "df_selected = df[selected_features + [\"OUTCOME\"]]\n",
    "\n",
    "# Salviamo il file CSV\n",
    "df_selected.to_csv(\"./data/relevant_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.io as sio  # Per salvare in .mat (MATLAB format)\n",
    "\n",
    "# 🔹 Carica il dataset (se non è già in memoria)\n",
    "df = pd.read_csv(\"./data/relevant_features.csv\")\n",
    "\n",
    "# 🔹 Seleziona solo le feature di input (senza OUTCOME)\n",
    "X = df.drop(columns=[\"OUTCOME\"])\n",
    "y = df[\"OUTCOME\"]\n",
    "\n",
    "# 🔹 Filtra solo dati normali per training e validation set\n",
    "df_normal = df[df[\"OUTCOME\"] == 0]\n",
    "df_anomaly = df[df[\"OUTCOME\"] == 1]\n",
    "\n",
    "# 🔹 Prendi i primi 9000 dati normali per il training set\n",
    "X_train = df_normal.iloc[:9000, :-1].values  # Escludi OUTCOME\n",
    "y_train = df_normal.iloc[:9000, -1].values  # Target\n",
    "\n",
    "# 🔹 Prendi i successivi 9000 dati normali per il validation set\n",
    "X_val = df_normal.iloc[9000:18000, :-1].values\n",
    "y_val = df_normal.iloc[9000:18000, -1].values\n",
    "\n",
    "# 🔹 Crea test set bilanciato (50% anomalie) - 1750 normali + 1750 anomalie\n",
    "X_test_balanced = pd.concat([df_normal.iloc[18000:19750, :-1], df_anomaly.iloc[:1750, :-1]]).values\n",
    "y_test_balanced = pd.concat([df_normal.iloc[18000:19750, -1], df_anomaly.iloc[:1750, -1]]).values\n",
    "\n",
    "# 🔹 Crea test set con 5% anomalie - 3325 normali + 175 anomalie\n",
    "X_test_5perc = pd.concat([df_normal.iloc[19750:23075, :-1], df_anomaly.iloc[1750:1925, :-1]]).values\n",
    "y_test_5perc = pd.concat([df_normal.iloc[19750:23075, -1], df_anomaly.iloc[1750:1925, -1]]).values\n",
    "\n",
    "# 🔹 Normalizza con MinMaxScaler (range [0,1])\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test_balanced = scaler.transform(X_test_balanced)\n",
    "X_test_5perc = scaler.transform(X_test_5perc)\n",
    "\n",
    "# 🔹 Salva i dataset in formato MATLAB (.mat) con array\n",
    "sio.savemat(\"./data/fuzzy_data.mat\", {\n",
    "    \"X_train\": X_train, \n",
    "    \"y_train\": y_train, \n",
    "    \"X_val\": X_val, \n",
    "    \"y_val\": y_val, \n",
    "    \"X_test_balanced\": X_test_balanced, \n",
    "    \"y_test_balanced\": y_test_balanced, \n",
    "    \"X_test_5perc\": X_test_5perc, \n",
    "    \"y_test_5perc\": y_test_5perc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_training and X_testing datasets\n",
    "X_train, X_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train = X_train[X_train.OUTCOME == 0]\n",
    "X_train = X_train.drop(['OUTCOME'], axis=1)\n",
    "\n",
    "y_test = X_test['OUTCOME']\n",
    "X_test = X_test.drop(['OUTCOME'], axis=1)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the autoencoder model and showing its summary\n",
    "ae = model = Sequential()\n",
    "model.add(Dense(35, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(X_train.shape[1]))\n",
    "\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "nb_epoch = 50\n",
    "batch_size = 64\n",
    "\n",
    "ae.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./model.SWAT.keras\", verbose=0)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "history = ae.fit(X_train, X_train, epochs=nb_epoch, batch_size=batch_size, shuffle=True,\n",
    "                 validation_data=(X_test, X_test), verbose=1, callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "ae = load_model('model.SWAT.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model loss over the amount of epochs\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "# plt.savefig('loss_SWAT_GoodModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model accuracy over the amount of epochs\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "# plt.savefig('accuracy_SWaT_GoodModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predictions of the autoencoder model on X_test testing sample\n",
    "predictions = ae.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MSE and reconstruction error\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class'] == 0) & (error_df['reconstruction_error'] < 0.1)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fraud_error_df = error_df[error_df['true_class'] == 1]\n",
    "_ = ax.hist(fraud_error_df.reconstruction_error.values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and plotting the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([-1,1],[-1,1],'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "# plt.savefig('ROC_SWAT2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Recall vs Precision plot\n",
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "# high precision = low false positive\n",
    "# high recall = low false negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting precision metrics for different threshold values to find optimal threshold\n",
    "plt.plot(th, precision[1:], 'b', label='Threshold-Precision curve')\n",
    "plt.title('Precision for different threshold values')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "# plt.savefig('precision_threshold_SWAT.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting recall metrics for different threshold values to find optimal threshold\n",
    "plt.plot(th, recall[1:], 'b', label='Threshold-Recall curve')\n",
    "plt.title('Recall for different threshold values')\n",
    "plt.xlabel('Reconstruction error')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the manual threshold\n",
    "threshold = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction error per datapoint index for the manually defined threshold\n",
    "groups = error_df.groupby('true_class')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Attack\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for different classes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show();\n",
    "# plt.savefig('Threshold SWaT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "threshold = 0.01\n",
    "LABELS = [\"Normal\", \"Attack\"]\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
